{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Jupyter Python notebook: returns_analysis\n",
    "Version: 0.3.35\n",
    "Date: 4/13/2021\n",
    "Author: Jarrod Wilcox\n",
    "Contact:  jarrod.wilcox@gmail.com\n",
    "License: M.I.T. license, distributed as is, suitable for education and research only.\n",
    "\n",
    "Oldest installable dependencies tested:  python 3.8.3, numpy 1.15.4, scipy 1.4.1, pandas 1.03, jupyter 1.0.0, cvxpy 1.1.1.\n",
    "\n",
    "This \"returns_analysis\" is research code that first reads a clean comma-delimited file, fully-populated, of asset prices adjusted for any distributions, or alternatively, of their returns.  It is written to be a pre-processor for the \"resilience_optimizer\" notebook.  Statistical reports, an optional log file, and output files are produced.  A top-down hierarchical clustering algorithm can help spot structural change and outliers.  Scenarios can be extracted from sub-matrices, including those with overlapping compound returns.  Scenarios are described by top-down hierachical clustering, standard statistics including mean, standard deviation, skewness, kurtosis, and correlations.  Return means can be shrunk toward priors that are input from user files.  The generated output files are available as input for the resilience optimizer.\n",
    "\n",
    "\n",
    "SAMPLE INPUTS:\n",
    "params=collections.OrderedDict(\n",
    "    namefile=None,\n",
    "    logfile='run013.txt',\n",
    "    sourcefile='saved_returns.csv',\n",
    "    sourcetype='RETURNS',\n",
    "    prior_file='group_priors.csv',\n",
    "    codefile='equiv.csv',\n",
    "    modify='shrink_means',\n",
    "    predict_file=\"prediction_01.csv\",\n",
    "    paramfile='params01.json',\n",
    "    logging=True,\n",
    "    verbose=True,\n",
    "    date_format='%m/%d/%y',\n",
    "    datebounds=[1980.00,2020.1],\n",
    "    scenario_dict={\n",
    "        'history':{'multiple':1,'datetimebounds':  ('1/31/88','2/5/21'),'interval':1,'smodify':True,'tdiscount':.03},\n",
    "        'breakdown':{'multiple':1,'datetimebounds':('6/30/07','7/31/09'),'interval':1,'smodify':False,'tdiscount':.03}, \n",
    "        '6_month':{'multiple':1,'datetimebounds':('1/31/88','2/5/21'),'interval':6,'smodify':True,'tdiscount':.03},\n",
    "        },\n",
    "    )\n",
    "    \n",
    "INPUT DESCRIPTIONS (note file samples may be found in the Github jarrodwilcox/resilience_lab repository):\n",
    "\n",
    "\n",
    "namefile:  Optional comma-delimited file (.csv) linking longer asset names to short tickers or other id's.\n",
    "\n",
    "logfile:  Path to a log file with all program text output written into it.  Used if logging=True.\n",
    "\n",
    "sourcefile:  Path to a csv file containing asset prices or returns, with top row containing tickers or other id's.  The left-most column contains dates (id = Date, date, or DATE) for each joint observation or scenario outcome.  This version of the program is written for monthly data.\n",
    "\n",
    "sourcetype: Either the string PRICES or RETURNS.\n",
    "\n",
    "prior_file: Path to a csv file containing broad asset return means, standard deviations, and the equivalent number of observations used to estimate them.\n",
    "\n",
    "codefile: Path to a csv file associating tickers or other id's to the broad asset classes contained in the prior_file.\n",
    "\n",
    "modify: String that controls whether returns in the sourcefile will be modified using the information contained in the codefile and priorfile.  Should be set to either 'shrink_means' or 'mirror'.\n",
    "\n",
    "predict_file: Path to an output file in the same format as the sourcefile.  It concatenates return matrices for one or more scenario-generators, ranging from simple history through disaster scenarios through scenarios with returns compounded over multiple periods.  In this version, all scenario generators are derived from the original sourcefile.\n",
    "\n",
    "paramfile: Path to a json output file containing these input parameters. \n",
    "\n",
    "logging:  Set either to True or False to determine whether a log file will be written.\n",
    "\n",
    "verbose: Set either to True or False to determine how extensive reports will be written.\n",
    "\n",
    "date_format: String to govern how Python reads the date column in the sourcefile.\n",
    "\n",
    "datebounds: Two element array of floating point dates in years, for easy trimming of the source return data before scenario generation.\n",
    "\n",
    "scenario_dict: Python dictionary of dictionaries incorporating descriptions of one or more scenario generators.  The top-level keys are names you supply for each scenario-generator.  Each of thes has subkeys 'multiple', 'datetimebounds','interval','smodify', and 'tdiscount', as described below.\n",
    "\n",
    "multiple:  Set at 1 or 0.  This governs whether the current run will generate data for that scenario-generator.\n",
    "\n",
    "datetimebounds: Tuple of string-formatted start and stop dates in the same format as in the sourcefile first column (use date_format) that apply to a particular scenario.  The bounds can be wider than available data.\n",
    "\n",
    "interval: For original monthly data, use the integer 1.  Higher integers specify that the scenario-generator will supply returns compounded over more than one month. Generated reports for compound returns incorporate measures intended to eliminate the biases resulting from overlapping observations.\n",
    "\n",
    "smodify:  A boolean True or False governing whether the return matrix for a particular scenario-generator will be modified.\n",
    "\n",
    "tdiscount: A floating point decimal fraction to be preserved in your paramfile dsignating a pure time discounting rate (.03 refers to 3% annually).  This is used when paramfile is read by the resilience_optimizer program.\n",
    "\n",
    "Sample data files are included in the repository.\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "Produces screen output, an optional logfile with a printout of program input and results, and writes input files for use with the resilience_optimizer program.\n",
    "    \n",
    "BACKGROUND READING:\n",
    "\n",
    "\"Better Portfolios with Higher Moments\" by Jarrod Wilcox, in the Journal of Asset Management for December,2020, provides further details on the benefits of non-parametric representations of asset return distributions, including their use in constructing more resilient portfolios managing non-normal returns.\n",
    "\n",
    "\"Expected Surplus Growth Compared with Meanâ€“Variance Optimization\", by Jarrod Wilcox and Stephen Satchell in \n",
    "The Journal of Portfolio Management Multi-Asset Special Issue 2021, 47 (4) 145-159; DOI: https://doi.org/10.3905/jpm.2021.1.209 provides further details on the approach.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys,collections  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from math import exp, isnan\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET PRIORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prior_file(prior_file=None):\n",
    "    if not prior_file is None:\n",
    "        try:\n",
    "            prior_file_df=pd.read_csv(prior_file)\n",
    "            return prior_file_df\n",
    "        except:\n",
    "            print('NO PRIOR_FILE FOUND')\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET ASSET CODES FOR PRIORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get asset group codes\n",
    "def load_asset_codes(codefile=None):\n",
    "    if not codefile is None:\n",
    "        try:\n",
    "            equivs_df=pd.read_csv(codefile)\n",
    "            return(equivs_df)\n",
    "        except:\n",
    "            print('NO ASSET CATEGORIZATION FOUND')\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(sourcefile):\n",
    "    try:\n",
    "        source=pd.read_csv(sourcefile)\n",
    "        \n",
    "        clist=source.columns.values #drop unnamed columns\n",
    "        for i,v in enumerate(clist): \n",
    "            if 'named' in v:\n",
    "                clist[i]= '_'+str(i)        \n",
    "        source.columns=clist\n",
    "        for i in clist:\n",
    "            if i[0]=='_':\n",
    "                source.drop([i], axis=1, inplace=True)\n",
    "                \n",
    "        temp=source.get('Date') #put assumed date column into dataframe index\n",
    "        if temp is None:\n",
    "            temp=source.get('DATE')\n",
    "        if not temp is None:\n",
    "            source.index=temp \n",
    "        try:\n",
    "            source.drop(['Date'],axis=1,inplace=True)\n",
    "        except:\n",
    "            try:\n",
    "                source.drop(['DATE'],axis=1,inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "        return source\n",
    "    except:\n",
    "        print('NO GOOD ' + sourcefile + ' FOUND')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK FOR PRIORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_priors(source_df,prior_file=None,codefile=None):\n",
    "    print()\n",
    "    if not (prior_file is None) and not(codefile is None):\n",
    "        priors_df=load_prior_file(prior_file)\n",
    "        asset_codes_df=load_asset_codes(codefile)        \n",
    "        for code in asset_codes_df['asset'].values:\n",
    "            if not code in priors_df['asset'].values:\n",
    "                print(code + 'not in '+prior_file)\n",
    "                raise\n",
    "        for tick in source_df.columns.values:\n",
    "            if not tick in asset_codes_df['ticker'].values:\n",
    "                print(tick + ' not in '+codefile)\n",
    "                raise\n",
    "        return (asset_codes_df,priors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert date string to year, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datestring(indates,dformat='%Y-%m-%d'):\n",
    "    dt=[datetime.strptime(d, dformat) for d in indates]\n",
    "    return [d.year-1+d.month/12. for d in dt]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATE RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price2return(prices):\n",
    "    '''converts monthly prices to monthly returns'''\n",
    "    returns=prices/prices.shift(1)\n",
    "    returns=returns[1:]-1.\n",
    "    returns_df=pd.DataFrame(returns,columns=prices.columns,index=prices.index[1:])   \n",
    "    return(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIFY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink_means(rtn_df,asset_codes_df,priors_df):\n",
    "\n",
    "    #prepare ticker: asset codes from possibly larger list to tie to asset priors\n",
    "    new_asset_codes_df=pd.DataFrame(rtn_df.columns.values,columns=['ticker'])\n",
    "    asset_dict={x[0]:x[1] for x in asset_codes_df.values}\n",
    "    new_asset_codes_df['asset']=[asset_dict.get(x) for x in rtn_df.columns.values]\n",
    "    missing=[v[0] for v in new_asset_codes_df.values if v[1] is None]\n",
    "    if len(missing)> 0:\n",
    "        print('The following have no priors associated')\n",
    "        raise\n",
    "        \n",
    "    #calculate observational statistics\n",
    "    means=np.mean(rtn_df.values,axis=0)\n",
    "    stds=np.std(rtn_df.values,axis=0)\n",
    "    stats_df=pd.DataFrame(np.array([means,stds]).T,columns=['o_mean','o_stdev'])\n",
    "    stats_df['o_N']=len(rtn_df)\n",
    "    stats_df['ticker']=rtn_df.columns.values\n",
    "    stats_df['o_precise']=stats_df['o_N']/(stats_df['o_stdev']**2)\n",
    "\n",
    "    #bring in prior information\n",
    "    temp_df=new_asset_codes_df.join(priors_df.set_index('asset'),on='asset')\n",
    "    temp_df['p_precise']=temp_df['p_N']/(temp_df['p_stdev']**2)\n",
    "\n",
    "    #combine to calulate shrinkage mean\n",
    "    calc_df=temp_df.join(stats_df.set_index('ticker'),on='ticker')\n",
    "\n",
    "    calc_df['t_precise']=calc_df['p_precise']+calc_df['o_precise']\n",
    "    calc_df['wt_p']=calc_df['p_precise']/calc_df['t_precise']\n",
    "    calc_df['wt_o']=calc_df['o_precise']/calc_df['t_precise']\n",
    "    calc_df['s_mean']=calc_df['wt_p']*calc_df['p_mean']+calc_df['wt_o']*calc_df['o_mean']\n",
    "\n",
    "    \n",
    "    #assemble for display and possible expansion to illustrate tail risk as well\n",
    "    calc_df=pd.DataFrame(calc_df[['o_mean','s_mean']])\n",
    "    calc_df['ticker']=stats_df['ticker']\n",
    "    calc_df=pd.DataFrame(calc_df[['ticker','o_mean','s_mean']])\n",
    "\n",
    "    #In return matrix, substitute column shrinkage means for column means\n",
    "    for row,tick in enumerate(calc_df['ticker'].values):\n",
    "        rtn_df[tick]=rtn_df[tick] + calc_df['s_mean'].values[row] - calc_df['o_mean'].values[row]\n",
    "\n",
    "    return rtn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_switch(rtn_df,modify, asset_codes_df=None,priors_df=None):\n",
    "    if modify=='shrink_means':\n",
    "        return shrink_means(rtn_df,asset_codes_df,priors_df)\n",
    "    else:\n",
    "        return rtn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPOUND RETURNS OVER RETURN INTERVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_compound_returns(returns_df,return_interval):\n",
    "    lrtns_df=np.log1p(returns_df)\n",
    "    roll_lrtns_df=lrtns_df.rolling(return_interval).sum()[return_interval:]\n",
    "    returns_df=np.exp(roll_lrtns_df)-1.0\n",
    "    return returns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLLECT FURTHER STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_rtn_summary(returns_df,return_interval):\n",
    "\n",
    "    tickers=returns_df.columns\n",
    "    \n",
    "    for i in range(return_interval):\n",
    "        rtns=returns_df.values[i:]\n",
    "        rtns=rtns[::return_interval]\n",
    "        print('len rtns: ',len(rtns))\n",
    "        means=np.mean(rtns,axis=0)\n",
    "        covs=np.cov(rtns.T)\n",
    "        stdevs=np.std(rtns,axis=0)\n",
    "        corr2=np.round_(np.corrcoef(rtns.T),2)        \n",
    "        corrs=np.corrcoef(rtns.T)\n",
    "        skews=stats.skew(rtns,axis=0)        \n",
    "        kurts=stats.kurtosis(rtns,axis=0,fisher=False)\n",
    "        if i==0:\n",
    "            count=len(rtns)\n",
    "            means_sum=means\n",
    "            covs_sum=covs\n",
    "            stdevs_sum=stdevs\n",
    "            corrs_sum=corrs\n",
    "            skews_sum=skews\n",
    "            kurts_sum=kurts\n",
    "        else:\n",
    "            means_sum+=means\n",
    "            covs_sum+=covs\n",
    "            stdevs_sum+=stdevs\n",
    "            corrs_sum+=corrs\n",
    "            skews_sum+=skews\n",
    "            kurts_sum+=kurts\n",
    "\n",
    "    means=np.divide(means_sum,return_interval)\n",
    "    covs=np.divide(covs_sum,return_interval)\n",
    "    stdevs=np.divide(stdevs_sum,return_interval)\n",
    "    corrs=np.divide(corrs_sum,return_interval)\n",
    "    skews=np.divide(skews_sum,return_interval)\n",
    "    kurts=np.divide(kurts_sum,return_interval)\n",
    "\n",
    "    corrs_df=pd.DataFrame(corrs,columns=tickers,index=tickers)\n",
    "    descript_df=pd.DataFrame({'TICKER':tickers,'MEAN':np.round(means,4),\n",
    "        'STDEV':np.round(stdevs,4),'SKEW':np.round(skews,2),'KURT':np.round(kurts,2)})\n",
    "    \n",
    "    return(descript_df,corrs_df,count) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESEARCH RECORDKEEPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters2(params):\n",
    "    for key,value in params.items():\n",
    "        print(\"{0}: {1}\".format(key,value))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATRIX SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(idxlist,square):\n",
    "    temp=np.copy(square)\n",
    "    size=len(square)*.9999    \n",
    "    while np.linalg.norm(temp,1)<size:\n",
    "        temp= np.corrcoef(temp.T)\n",
    "    #now split the list by index and labels\n",
    "    idx1=[idxlist[i] for i,v in enumerate(temp[0]) if v>0.]\n",
    "    idx2=[idxlist[i] for i,v in enumerate(temp[0]) if v<= 0.]    \n",
    "    return (idx1,idx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARE NEW SQUARE SUB-MATRIX FOR SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squareit(task,master):    \n",
    "    temp1=np.array([row for i,row in enumerate(master) if i in task])\n",
    "    temp1T=temp1.T\n",
    "    temp2=np.array([row for i,row in enumerate(temp1T) if i in task])\n",
    "    return temp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAVERSE POTENTIAL CLUSTER TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(matrix_df):\n",
    "    labels=matrix_df.columns.values    \n",
    "    idxs=[i for i,v in enumerate(labels)]\n",
    "    idx_dict={i:\"C\" for i in idxs}\n",
    "    \n",
    "    master=matrix_df.values\n",
    "\n",
    "    taskno=0\n",
    "    tasklist=[idxs]\n",
    "    while len(tasklist)>taskno:\n",
    "        task=tasklist[taskno]\n",
    "        if len(task)>2:\n",
    "            split_input=squareit(task,master)        \n",
    "            idx1,idx2=split(task,split_input)       \n",
    "            for v in idx1:\n",
    "                idx_dict[v] += '1'\n",
    "            for v in idx2:\n",
    "                idx_dict[v] += '2'\n",
    "            tasklist.append(idx1)\n",
    "            tasklist.append(idx2)\n",
    "        taskno+=1\n",
    "    output1=[[v,idx_dict[i]] for i,v in enumerate(labels)]\n",
    "    output2=pd.DataFrame(output1,columns=['ID','CLUSTER'])\n",
    "    output1=output2.sort_values(by=['CLUSTER'])\n",
    "    return output1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATISTICS SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_summary(returns_df,return_interval,verbose=False,namefile=None):\n",
    "    #CALCULATE RETURN STATISTICS AND SQUARE MATRICES -- COVARIANCE AND CORRELATIONS\n",
    "    #following improves estimates if overlapping observations\n",
    "    descript_df,corrs_df,count=overlap_rtn_summary(returns_df,return_interval)\n",
    "    print(' ')\n",
    "    print('CLUSTER ANALYSIS')\n",
    "    cluster_df=traverse(corrs_df) #CLUSTER ANALYSIS\n",
    "    try:\n",
    "        if not namefile is None:\n",
    "            names_df=pd.read_csv(namefile)\n",
    "            names_dict={x[0]:x[1] for x in zip(names_df['ID'].values,names_df['NAME'])}\n",
    "            cluster_df['NAME']=[names_dict[x] for x in cluster_df['ID']]\n",
    "    except:\n",
    "        print('namefile not located')\n",
    "        raise\n",
    "    \n",
    "    print(cluster_df.to_string(index=False))\n",
    "    print(' ')\n",
    "   \n",
    "    print('DISTRIBUTION STATISTICS')\n",
    "    descript_df=descript_df.reindex(cluster_df.index)\n",
    "    print(descript_df.to_string(index=False))\n",
    "    if verbose:\n",
    "        print(' ')\n",
    "        print('CORRELATIONS')\n",
    "        corrs_df.index=range(len(returns_df.columns)) #needed to put in same indix set as used for reindexing\n",
    "        corrs_df=corrs_df.reindex(cluster_df.index)\n",
    "        corrs_df=pd.DataFrame(corrs_df,columns=cluster_df['ID'].values)\n",
    "        corrs_df.index=corrs_df.columns\n",
    "        pd.set_option('display.max_rows',None)\n",
    "        pd.set_option('display.max_columns',None)\n",
    "        print(corrs_df)\n",
    "        pd.reset_option(\"all\")\n",
    "        print(' ')\n",
    "    \n",
    "\n",
    "    return (descript_df,corrs_df,count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HISTORY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_analysis(params,data_df):\n",
    "    \n",
    "    namefile=params.get('namefile')\n",
    "    sourcefile=params.get('sourcefile')\n",
    "    sourcetype=params.get('sourcetype')\n",
    "    return_interval=params.get('return_interval')\n",
    "    verbose=params.get('verbose')\n",
    "    date_format=params.get('date_format')\n",
    "    datebounds=params.get('datebounds')\n",
    "    \n",
    "    #READ IN PRICES OR RETURNS, PROVIDE RETURNS\n",
    "    try:\n",
    "        data_df=load_source(sourcefile)\n",
    "        print('type data_df: ',type(data_df))\n",
    "    except:\n",
    "        print(\"Can't read data.\")\n",
    "        raise\n",
    "        \n",
    "    if not (sourcetype=='PRICES' or sourcetype=='RETURNS'):\n",
    "        print('UNABLE TO DETERMINE SOURCE TYPE')\n",
    "        raise\n",
    "        \n",
    "    if sourcetype=='PRICES':\n",
    "        print('sourcetype: ',sourcetype)\n",
    "        returns_df=price2return(data_df)\n",
    "        returns_df.to_csv('saved_returns.csv')                \n",
    "    elif sourcetype=='RETURNS':\n",
    "        returns_df=data_df\n",
    "    \n",
    "    #TRIM SAMPLE BY DATE BOUNDS\n",
    "    if returns_df.index.name in ['Date','DATE','date']:        \n",
    "        print('datebounds: ',datebounds)        \n",
    "        print('date_format: ',date_format)\n",
    "        try:\n",
    "            returns_df['temp']=[datetime.strptime(d,date_format) for d in returns_df.index.values]\n",
    "        except:\n",
    "            print('can not read date as formatted')\n",
    "            raise\n",
    "        returns_df['year']=returns_df['temp'].dt.year\n",
    "        returns_df['month']=returns_df['temp'].dt.month\n",
    "        returns_df['day']=returns_df['temp'].dt.day\n",
    "        returns_df['gdate']=round(returns_df['year']-1+ returns_df['month']/12.,2)\n",
    "        returns_df.drop(['temp','year','month','day'],inplace=True,axis=1)\n",
    "        gdates=returns_df['gdate'].values\n",
    "        try:    \n",
    "            returns_df=returns_df.loc[returns_df['gdate']>=datebounds[0]]\n",
    "            returns_df=returns_df.loc[returns_df['gdate']<=datebounds[1]]\n",
    "            returns_df.drop(['gdate'],inplace=True,axis=1)\n",
    "        except:\n",
    "            print ('incorrect datebounds!')\n",
    "            raise\n",
    "    \n",
    "    if verbose:\n",
    "\n",
    "        print(' ')\n",
    "        print('RETURNS HEAD')\n",
    "        print(returns_df.head(5))\n",
    "        print(' ')\n",
    "        print('RETURNS TAIL')\n",
    "        print(returns_df.tail(5))\n",
    "    \n",
    "    #assume 1 as interval for history\n",
    "    descript_df,corrs_df,count=stat_summary(returns_df,1,verbose, namefile=None)\n",
    "\n",
    "    return(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACT SCENARIO FROM HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extract(returns_df,scenario_name,params):\n",
    "    date_format=params['date_format']\n",
    "    scenario=params.get('scenario_dict')[scenario_name]\n",
    "    early,late=scenario['datetimebounds']\n",
    "    early=datetime.strptime(early,date_format)\n",
    "    late=datetime.strptime(late,date_format)\n",
    "\n",
    "    temp_df=returns_df.copy()\n",
    "    temp_df['temp']=[datetime.strptime(d,date_format) for d in returns_df.index.values]\n",
    "    temp_df=temp_df.loc[temp_df['temp']>=early]\n",
    "    temp_df=temp_df.loc[temp_df['temp']<=late]\n",
    "    temp_df.drop(['temp'],axis=1,inplace=True)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCENARIO ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_extract(params,hist_returns_df,asset_codes_df=None,priors_df=None):\n",
    "    return_interval=params.get('return_interval')  \n",
    "    verbose=params.get('verbose')\n",
    "    scenario_dict=params.get('scenario_dict') \n",
    "    modify=params.get('modify')\n",
    "    prediction_sample_length={}    \n",
    "    prediction_df=None\n",
    "    \n",
    "    intervals=[]\n",
    "    for i,key in enumerate(scenario_dict.keys()):\n",
    "        properties=scenario_dict[key]\n",
    "        multiple=int(properties['multiple'])        \n",
    "        if multiple>=1:\n",
    "            #SCENARIO PROPERTIES\n",
    "            print(' ')\n",
    "            print('SCENARIO')\n",
    "            scenario_name=key\n",
    "            print('scenario_name: ',scenario_name)\n",
    "            print('multiple: ',multiple)\n",
    "            dates=properties['datetimebounds']\n",
    "            print('dates: ',dates)\n",
    "            interval=properties.get('interval')\n",
    "            if interval is None: #use default if no interval specified for scenario\n",
    "                interval=1\n",
    "            print('interval: ',interval)\n",
    "            intervals.append(interval)\n",
    "           \n",
    "            smodify=properties['smodify']\n",
    "            \n",
    "            #GET SCENARIO DATA           \n",
    "            scenario_return_df=data_extract(hist_returns_df,scenario_name,params)\n",
    "            \n",
    "            #MODIFICATION -- shrinkage and compounding\n",
    "            if smodify:\n",
    "                #note switch is extra hook for future use\n",
    "                print('MEANS SHRUNK TOWARD ASSET PRIORS')\n",
    "                scenario_return_df=modify_switch(scenario_return_df,modify,asset_codes_df,priors_df)    \n",
    "            scenario_return_df=calculate_compound_returns(scenario_return_df,interval)\n",
    "                \n",
    "            if verbose:\n",
    "                print('SCENARIO HEAD')\n",
    "                print(scenario_return_df.head(5))\n",
    "                print(' ')\n",
    "                print('SCENARIO TAIL')\n",
    "                print(scenario_return_df.tail(5))\n",
    "                print(' ')\n",
    "                \n",
    "            print(' ')\n",
    "            print('SCENARIO WITH INTERVAL '+str(interval))                   \n",
    "            descript_df,corrs_df,count=stat_summary(scenario_return_df,interval,verbose, namefile=None)\n",
    "            \n",
    "            #MULTIPLY ROWS IF DESIRED (OBSOLETE!) \n",
    "            scenario_return_df=pd.concat([scenario_return_df]*multiple,ignore_index=True) #drop dates\n",
    "            \n",
    "            #LABEL SCENARIO SOURCE\n",
    "            scenario_return_df.index=[scenario_name]*len(scenario_return_df) #label scenario source\n",
    "            \n",
    "            #APPEND TO PREDICTION DISTRIBUTION LIST\n",
    "            if prediction_df is None:                \n",
    "                prediction_df=scenario_return_df.copy()                \n",
    "            else:           \n",
    "                prediction_df=pd.concat([prediction_df,scenario_return_df])                \n",
    "            if not scenario_return_df is None:    \n",
    "                prediction_sample_length[scenario_name]=len(scenario_return_df)               \n",
    "            scenario_return_df=None #cleanup for next iteration\n",
    "            \n",
    "    print(' ')\n",
    "    print('SCENARIO SAMPLE LENGTHS')\n",
    "    for key in prediction_sample_length.keys():\n",
    "        print(key + ': '+str(prediction_sample_length[key]))\n",
    "    print(' ')\n",
    "    test=(float(intervals[0])==sum(intervals)/len(intervals))\n",
    "    if test:  #if all intervals on same scale\n",
    "        print('PREDICTION DISTRIBUTION')\n",
    "        #assume 1 for interval after compounding already\n",
    "        stat_summary(prediction_df,1,verbose)\n",
    "    else:\n",
    "        print('NOTE: PREDICTION DISTRIBUTION INCLUDES DIFFERENT SCALES')\n",
    "\n",
    "    return prediction_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETURN MATRIX GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_matrix_generator(params={}):    \n",
    "    namefile=params.get('namefile')\n",
    "    logfile=params.get('logfile')\n",
    "    predict_file=params.get('predict_file')\n",
    "    sourcefile=params.get('sourcefile')\n",
    "    sourcetype=params.get('sourcetype')    \n",
    "    logging=params.get('logging')\n",
    "    verbose=params.get('verbose')\n",
    "    date_format=params.get('date_format')\n",
    "    datebounds=params.get('datebounds')\n",
    "    scenario_dict=params.get('scenario_dict')\n",
    "    prior_file=params.get('prior_file')\n",
    "    codefile=params.get('codefile')\n",
    "    modify=params.get('modify')\n",
    "    \n",
    "    # START LOGGING IF SELECTED\n",
    "    if logging:\n",
    "        orig_stdout = sys.stdout\n",
    "        #record results in logfile\n",
    "        f = open(logfile, 'w')\n",
    "        sys.stdout = f\n",
    "    \n",
    "        #record control parameters\n",
    "        print_parameters2(params)\n",
    "    \n",
    "    # READ NECESSARY FILES\n",
    "    source_df=load_source(sourcefile)\n",
    "    print(source_df.head(3))\n",
    "    asset_codes_df=priors_df=None\n",
    "    if not modify is None:\n",
    "        asset_codes_df,priors_df=check_priors(source_df,prior_file,codefile)\n",
    "   \n",
    "    # HISTORY ANALYSIS\n",
    "    returns_df=history_analysis(params,source_df)\n",
    "    \n",
    "    # SCENARIO GENERATION, ANALYSIS AND COMPOSITION TO PREDICTION DISTRIBUTION\n",
    "    if not modify is None: #needs work if multiple options for modify\n",
    "        prediction_df=scenario_extract(params,returns_df,asset_codes_df,priors_df)\n",
    "    else:\n",
    "        prediction_df=scenario_extract(params,returns_df)\n",
    "    prediction_df.to_csv(predict_file)\n",
    "    \n",
    "    # EXIT\n",
    "    if logging:\n",
    "        #close logfile and print it on terminal\n",
    "        f.close()\n",
    "        sys.stdout = orig_stdout\n",
    "\n",
    "        h=open(logfile,'r')\n",
    "        for line in h:         \n",
    "            print(line[:-1])          \n",
    "        h.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN: SET PARAMETERS AND CALL RETURN MATRIX GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  VWEHX_IYR  XLP_DIA_XLY  \\\n",
      "Date                                                                     \n",
      "1/1/03        -0.021238 -0.018220    -0.015333   0.000518    -0.029868   \n",
      "2/1/03        -0.018300 -0.015633    -0.007872   0.013043    -0.017791   \n",
      "3/1/03        -0.037137  0.007417     0.004197   0.008358     0.008755   \n",
      "\n",
      "         IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  VWAHX_VWLTX  \\\n",
      "Date                                                                   \n",
      "1/1/03 -0.007733         0.000027  -0.000267   0.045035    -0.008034   \n",
      "2/1/03 -0.018561         0.015181   0.029149   0.030724     0.016477   \n",
      "3/1/03  0.051434        -0.004663  -0.015579  -0.027374    -0.001245   \n",
      "\n",
      "        VWESX_LQD  \n",
      "Date               \n",
      "1/1/03   0.001198  \n",
      "2/1/03   0.022794  \n",
      "3/1/03  -0.005009  \n",
      "\n",
      "type data_df:  <class 'pandas.core.frame.DataFrame'>\n",
      "datebounds:  [1980.0, 2020.1]\n",
      "date_format:  %m/%d/%y\n",
      " \n",
      "RETURNS HEAD\n",
      "        EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  VWEHX_IYR  XLP_DIA_XLY  \\\n",
      "Date                                                                     \n",
      "1/1/03        -0.021238 -0.018220    -0.015333   0.000518    -0.029868   \n",
      "2/1/03        -0.018300 -0.015633    -0.007872   0.013043    -0.017791   \n",
      "3/1/03        -0.037137  0.007417     0.004197   0.008358     0.008755   \n",
      "4/1/03         0.089841  0.076257     0.081563   0.041336     0.072799   \n",
      "5/1/03         0.067663  0.087844     0.076409   0.032660     0.050201   \n",
      "\n",
      "         IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  VWAHX_VWLTX  \\\n",
      "Date                                                                   \n",
      "1/1/03 -0.007733         0.000027  -0.000267   0.045035    -0.008034   \n",
      "2/1/03 -0.018561         0.015181   0.029149   0.030724     0.016477   \n",
      "3/1/03  0.051434        -0.004663  -0.015579  -0.027374    -0.001245   \n",
      "4/1/03  0.077433         0.002676   0.009582  -0.017243     0.011385   \n",
      "5/1/03  0.104218         0.022747   0.059440   0.004613     0.027824   \n",
      "\n",
      "        VWESX_LQD  \n",
      "Date               \n",
      "1/1/03   0.001198  \n",
      "2/1/03   0.022794  \n",
      "3/1/03  -0.005009  \n",
      "4/1/03   0.022546  \n",
      "5/1/03   0.045786  \n",
      " \n",
      "RETURNS TAIL\n",
      "         EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  VWEHX_IYR  XLP_DIA_XLY  \\\n",
      "Date                                                                      \n",
      "9/1/20         -0.012448 -0.025809    -0.037349  -0.018683    -0.021671   \n",
      "10/1/20        -0.022323  0.012535    -0.022176  -0.009734    -0.030225   \n",
      "11/1/20         0.133743  0.139629     0.118635   0.057833     0.098055   \n",
      "12/1/20         0.044042  0.042117     0.044086   0.014860     0.021217   \n",
      "1/1/21          0.009096  0.001352    -0.005022   0.001593    -0.016665   \n",
      "\n",
      "          IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  VWAHX_VWLTX  \\\n",
      "Date                                                                    \n",
      "9/1/20  -0.013540         0.001262   0.007839  -0.020763    -0.000509   \n",
      "10/1/20 -0.033651        -0.006740  -0.032882  -0.002503    -0.000917   \n",
      "11/1/20  0.094709         0.001998   0.016003  -0.026384     0.018066   \n",
      "12/1/20  0.039309        -0.010877  -0.046243   0.035760     0.006996   \n",
      "1/1/21   0.039528        -0.004544  -0.034205  -0.015492     0.009433   \n",
      "\n",
      "         VWESX_LQD  \n",
      "Date                \n",
      "9/1/20   -0.002971  \n",
      "10/1/20  -0.009734  \n",
      "11/1/20   0.042915  \n",
      "12/1/20  -0.016214  \n",
      "1/1/21   -0.021626  \n",
      "len rtns:  217\n",
      " \n",
      "CLUSTER ANALYSIS\n",
      "             ID CLUSTER\n",
      "EFA_EZU_EEM_EWJ   C1111\n",
      "        IWR_IWS  C11121\n",
      "    IWP_SPY_XLK  C11121\n",
      "    XLP_DIA_XLY  C11122\n",
      "      VWEHX_IYR    C112\n",
      "        IBB_XLV     C12\n",
      "IEF_VFITX_VFIIX   C2111\n",
      "      VUSTX_TLT   C2111\n",
      "      VWESX_LQD   C2112\n",
      "    VWAHX_VWLTX    C212\n",
      "      GLD_VWSTX     C22\n",
      " \n",
      "DISTRIBUTION STATISTICS\n",
      "         TICKER   MEAN  STDEV  SKEW  KURT\n",
      "EFA_EZU_EEM_EWJ 0.0078 0.0508 -0.56  4.59\n",
      "        IWR_IWS 0.0101 0.0488 -0.88  7.32\n",
      "    IWP_SPY_XLK 0.0110 0.0451 -0.51  4.64\n",
      "    XLP_DIA_XLY 0.0094 0.0381 -0.47  4.75\n",
      "      VWEHX_IYR 0.0075 0.0398 -1.03 12.08\n",
      "        IBB_XLV 0.0107 0.0459 -0.32  3.46\n",
      "IEF_VFITX_VFIIX 0.0031 0.0128 -0.02  5.04\n",
      "      VUSTX_TLT 0.0052 0.0352  0.44  4.43\n",
      "      VWESX_LQD 0.0052 0.0237  0.22  7.16\n",
      "    VWAHX_VWLTX 0.0040 0.0140 -0.96  6.39\n",
      "      GLD_VWSTX 0.0053 0.0250  0.01  3.17\n",
      " \n",
      "CORRELATIONS\n",
      "                 EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  XLP_DIA_XLY  \\\n",
      "EFA_EZU_EEM_EWJ         1.000000  0.849353     0.849997     0.808115   \n",
      "IWR_IWS                 0.849353  1.000000     0.943718     0.915046   \n",
      "IWP_SPY_XLK             0.849997  0.943718     1.000000     0.927407   \n",
      "XLP_DIA_XLY             0.808115  0.915046     0.927407     1.000000   \n",
      "VWEHX_IYR               0.733025  0.833001     0.747191     0.752495   \n",
      "IBB_XLV                 0.622441  0.698031     0.719410     0.708906   \n",
      "IEF_VFITX_VFIIX        -0.150194 -0.251555    -0.253129    -0.192327   \n",
      "VUSTX_TLT              -0.225243 -0.282028    -0.289613    -0.233347   \n",
      "VWESX_LQD               0.301053  0.269755     0.227650     0.238077   \n",
      "VWAHX_VWLTX             0.188897  0.197806     0.171217     0.135040   \n",
      "GLD_VWSTX               0.176238  0.067253     0.059422     0.034748   \n",
      "\n",
      "                 VWEHX_IYR   IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  VWESX_LQD  \\\n",
      "EFA_EZU_EEM_EWJ   0.733025  0.622441        -0.150194  -0.225243   0.301053   \n",
      "IWR_IWS           0.833001  0.698031        -0.251555  -0.282028   0.269755   \n",
      "IWP_SPY_XLK       0.747191  0.719410        -0.253129  -0.289613   0.227650   \n",
      "XLP_DIA_XLY       0.752495  0.708906        -0.192327  -0.233347   0.238077   \n",
      "VWEHX_IYR         1.000000  0.560758        -0.023217  -0.045859   0.461213   \n",
      "IBB_XLV           0.560758  1.000000        -0.122845  -0.137221   0.238363   \n",
      "IEF_VFITX_VFIIX  -0.023217 -0.122845         1.000000   0.878996   0.644748   \n",
      "VUSTX_TLT        -0.045859 -0.137221         0.878996   1.000000   0.695428   \n",
      "VWESX_LQD         0.461213  0.238363         0.644748   0.695428   1.000000   \n",
      "VWAHX_VWLTX       0.382432  0.105761         0.397927   0.382877   0.583380   \n",
      "GLD_VWSTX         0.138558  0.049635         0.326613   0.224353   0.297666   \n",
      "\n",
      "                 VWAHX_VWLTX  GLD_VWSTX  \n",
      "EFA_EZU_EEM_EWJ     0.188897   0.176238  \n",
      "IWR_IWS             0.197806   0.067253  \n",
      "IWP_SPY_XLK         0.171217   0.059422  \n",
      "XLP_DIA_XLY         0.135040   0.034748  \n",
      "VWEHX_IYR           0.382432   0.138558  \n",
      "IBB_XLV             0.105761   0.049635  \n",
      "IEF_VFITX_VFIIX     0.397927   0.326613  \n",
      "VUSTX_TLT           0.382877   0.224353  \n",
      "VWESX_LQD           0.583380   0.297666  \n",
      "VWAHX_VWLTX         1.000000   0.159661  \n",
      "GLD_VWSTX           0.159661   1.000000  \n",
      "As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n",
      "\n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarrod/pydev2/venv/lib/python3.9/site-packages/pandas/_config/config.py:620: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n",
      "  warnings.warn(d.msg, FutureWarning)\n",
      "/Users/jarrod/pydev2/venv/lib/python3.9/site-packages/pandas/_config/config.py:620: FutureWarning: \n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      "  warnings.warn(d.msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "SCENARIO\n",
      "scenario_name:  history\n",
      "multiple:  1\n",
      "dates:  ('1/31/88', '2/5/21')\n",
      "interval:  1\n",
      "MEANS SHRUNK TOWARD ASSET PRIORS\n",
      "SCENARIO HEAD\n",
      "        EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  VWEHX_IYR  XLP_DIA_XLY  \\\n",
      "Date                                                                     \n",
      "2/1/03        -0.016720 -0.015804    -0.008673   0.014663    -0.017450   \n",
      "3/1/03        -0.035557  0.007246     0.003396   0.009978     0.009095   \n",
      "4/1/03         0.091421  0.076086     0.080762   0.042956     0.073140   \n",
      "5/1/03         0.069243  0.087673     0.075608   0.034280     0.050542   \n",
      "6/1/03         0.035464  0.008137     0.010966   0.012890     0.010895   \n",
      "\n",
      "         IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  VWAHX_VWLTX  \\\n",
      "Date                                                                   \n",
      "2/1/03 -0.019122         0.016027   0.029266   0.029337     0.017061   \n",
      "3/1/03  0.050872        -0.003817  -0.015462  -0.028761    -0.000662   \n",
      "4/1/03  0.076872         0.003522   0.009699  -0.018630     0.011968   \n",
      "5/1/03  0.103657         0.023593   0.059557   0.003226     0.028407   \n",
      "6/1/03  0.012167        -0.001766  -0.015752   0.035435    -0.006473   \n",
      "\n",
      "        VWESX_LQD  \n",
      "Date               \n",
      "2/1/03   0.022864  \n",
      "3/1/03  -0.004939  \n",
      "4/1/03   0.022616  \n",
      "5/1/03   0.045856  \n",
      "6/1/03  -0.006482  \n",
      " \n",
      "SCENARIO TAIL\n",
      "         EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  VWEHX_IYR  XLP_DIA_XLY  \\\n",
      "Date                                                                      \n",
      "9/1/20         -0.010869 -0.025980    -0.038150  -0.017063    -0.021330   \n",
      "10/1/20        -0.020744  0.012364    -0.022977  -0.008114    -0.029885   \n",
      "11/1/20         0.135323  0.139457     0.117834   0.059453     0.098396   \n",
      "12/1/20         0.045622  0.041946     0.043285   0.016480     0.021557   \n",
      "1/1/21          0.010675  0.001181    -0.005823   0.003213    -0.016324   \n",
      "\n",
      "          IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  VWAHX_VWLTX  \\\n",
      "Date                                                                    \n",
      "9/1/20  -0.014101         0.002108   0.007956  -0.022150     0.000074   \n",
      "10/1/20 -0.034213        -0.005894  -0.032764  -0.003890    -0.000334   \n",
      "11/1/20  0.094148         0.002844   0.016120  -0.027771     0.018649   \n",
      "12/1/20  0.038748        -0.010031  -0.046126   0.034373     0.007580   \n",
      "1/1/21   0.038967        -0.003698  -0.034088  -0.016879     0.010017   \n",
      "\n",
      "         VWESX_LQD  \n",
      "Date                \n",
      "9/1/20   -0.002901  \n",
      "10/1/20  -0.009664  \n",
      "11/1/20   0.042985  \n",
      "12/1/20  -0.016144  \n",
      "1/1/21   -0.021556  \n",
      " \n",
      " \n",
      "SCENARIO WITH INTERVAL 1\n",
      "len rtns:  216\n",
      " \n",
      "CLUSTER ANALYSIS\n",
      "             ID CLUSTER\n",
      "EFA_EZU_EEM_EWJ   C1111\n",
      "        IWR_IWS  C11121\n",
      "    IWP_SPY_XLK  C11121\n",
      "    XLP_DIA_XLY  C11122\n",
      "      VWEHX_IYR    C112\n",
      "        IBB_XLV     C12\n",
      "IEF_VFITX_VFIIX   C2111\n",
      "      VUSTX_TLT   C2111\n",
      "      VWESX_LQD   C2112\n",
      "    VWAHX_VWLTX    C212\n",
      "      GLD_VWSTX     C22\n",
      " \n",
      "DISTRIBUTION STATISTICS\n",
      "         TICKER   MEAN  STDEV  SKEW  KURT\n",
      "EFA_EZU_EEM_EWJ 0.0095 0.0509 -0.57  4.58\n",
      "        IWR_IWS 0.0101 0.0489 -0.89  7.32\n",
      "    IWP_SPY_XLK 0.0103 0.0451 -0.52  4.63\n",
      "    XLP_DIA_XLY 0.0099 0.0381 -0.48  4.78\n",
      "      VWEHX_IYR 0.0091 0.0399 -1.03 12.03\n",
      "        IBB_XLV 0.0102 0.0460 -0.32  3.45\n",
      "IEF_VFITX_VFIIX 0.0040 0.0128 -0.02  5.02\n",
      "      VUSTX_TLT 0.0053 0.0353  0.44  4.41\n",
      "      VWESX_LQD 0.0053 0.0237  0.22  7.13\n",
      "    VWAHX_VWLTX 0.0046 0.0141 -0.97  6.42\n",
      "      GLD_VWSTX 0.0037 0.0249  0.01  3.20\n",
      " \n",
      "CORRELATIONS\n",
      "                 EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  XLP_DIA_XLY  \\\n",
      "EFA_EZU_EEM_EWJ         1.000000  0.849121     0.849764     0.807984   \n",
      "IWR_IWS                 0.849121  1.000000     0.943629     0.915238   \n",
      "IWP_SPY_XLK             0.849764  0.943629     1.000000     0.927630   \n",
      "XLP_DIA_XLY             0.807984  0.915238     0.927630     1.000000   \n",
      "VWEHX_IYR               0.733170  0.833242     0.747363     0.753567   \n",
      "IBB_XLV                 0.622082  0.697758     0.719161     0.708998   \n",
      "IEF_VFITX_VFIIX        -0.150972 -0.252441    -0.254023    -0.193987   \n",
      "VUSTX_TLT              -0.225834 -0.282678    -0.290275    -0.234669   \n",
      "VWESX_LQD               0.300854  0.269529     0.227388     0.237872   \n",
      "VWAHX_VWLTX             0.187093  0.195992     0.169324     0.131515   \n",
      "GLD_VWSTX               0.181652  0.072010     0.064155     0.042679   \n",
      "\n",
      "                 VWEHX_IYR   IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  VWESX_LQD  \\\n",
      "EFA_EZU_EEM_EWJ   0.733170  0.622082        -0.150972  -0.225834   0.300854   \n",
      "IWR_IWS           0.833242  0.697758        -0.252441  -0.282678   0.269529   \n",
      "IWP_SPY_XLK       0.747363  0.719161        -0.254023  -0.290275   0.227388   \n",
      "XLP_DIA_XLY       0.753567  0.708998        -0.193987  -0.234669   0.237872   \n",
      "VWEHX_IYR         1.000000  0.560683        -0.023418  -0.045989   0.461140   \n",
      "IBB_XLV           0.560683  1.000000        -0.123359  -0.137565   0.238154   \n",
      "IEF_VFITX_VFIIX  -0.023418 -0.123359         1.000000   0.878992   0.644688   \n",
      "VUSTX_TLT        -0.045989 -0.137565         0.878992   1.000000   0.695392   \n",
      "VWESX_LQD         0.461140  0.238154         0.644688   0.695392   1.000000   \n",
      "VWAHX_VWLTX       0.382416  0.104390         0.397692   0.382936   0.583738   \n",
      "GLD_VWSTX         0.140677  0.052919         0.330387   0.226831   0.300695   \n",
      "\n",
      "                 VWAHX_VWLTX  GLD_VWSTX  \n",
      "EFA_EZU_EEM_EWJ     0.187093   0.181652  \n",
      "IWR_IWS             0.195992   0.072010  \n",
      "IWP_SPY_XLK         0.169324   0.064155  \n",
      "XLP_DIA_XLY         0.131515   0.042679  \n",
      "VWEHX_IYR           0.382416   0.140677  \n",
      "IBB_XLV             0.104390   0.052919  \n",
      "IEF_VFITX_VFIIX     0.397692   0.330387  \n",
      "VUSTX_TLT           0.382936   0.226831  \n",
      "VWESX_LQD           0.583738   0.300695  \n",
      "VWAHX_VWLTX         1.000000   0.167212  \n",
      "GLD_VWSTX           0.167212   1.000000  \n",
      "As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n",
      "\n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      " \n",
      " \n",
      "SCENARIO\n",
      "scenario_name:  breakdown\n",
      "multiple:  1\n",
      "dates:  ('6/30/07', '7/31/09')\n",
      "interval:  1\n",
      "SCENARIO HEAD\n",
      "         EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  VWEHX_IYR  XLP_DIA_XLY  \\\n",
      "Date                                                                      \n",
      "8/1/07         -0.005284  0.000127     0.012618   0.035554     0.013433   \n",
      "9/1/07          0.061548  0.024958     0.035655   0.030224     0.024337   \n",
      "10/1/07         0.053035  0.013562     0.033510   0.010458     0.006703   \n",
      "11/1/07        -0.040168 -0.050312    -0.052614  -0.054919    -0.020174   \n",
      "12/1/07        -0.042202 -0.015103    -0.000182  -0.028533    -0.026263   \n",
      "\n",
      "          IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  VWAHX_VWLTX  \\\n",
      "Date                                                                    \n",
      "8/1/07   0.029537         0.018266   0.018810   0.007321    -0.007215   \n",
      "9/1/07   0.038792         0.004667   0.002178   0.054987     0.014739   \n",
      "10/1/07  0.032858         0.009892   0.016165   0.036524     0.003821   \n",
      "11/1/07 -0.007179         0.032517   0.049174  -0.005829     0.004355   \n",
      "12/1/07 -0.034180         0.000046  -0.008697   0.035610     0.000521   \n",
      "\n",
      "         VWESX_LQD  \n",
      "Date                \n",
      "8/1/07    0.016566  \n",
      "9/1/07    0.007334  \n",
      "10/1/07   0.013455  \n",
      "11/1/07   0.013115  \n",
      "12/1/07  -0.008721  \n",
      " \n",
      "SCENARIO TAIL\n",
      "        EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  VWEHX_IYR  XLP_DIA_XLY  \\\n",
      "Date                                                                     \n",
      "3/1/09         0.105900  0.078035     0.089365   0.015664     0.078104   \n",
      "4/1/09         0.123630  0.170056     0.121723   0.202348     0.106636   \n",
      "5/1/09         0.131113  0.038551     0.044625   0.033124     0.030295   \n",
      "6/1/09        -0.026350  0.003203     0.010233  -0.010960    -0.004323   \n",
      "7/1/09         0.107856  0.085596     0.080124   0.090243     0.086890   \n",
      "\n",
      "         IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  VWAHX_VWLTX  \\\n",
      "Date                                                                   \n",
      "3/1/09  0.052765         0.023963   0.030080  -0.011704    -0.003291   \n",
      "4/1/09 -0.004004        -0.013835  -0.059733  -0.014993     0.027772   \n",
      "5/1/09  0.050458        -0.010067  -0.032011   0.051795     0.020748   \n",
      "6/1/09  0.047218        -0.003034   0.007252  -0.025143    -0.008683   \n",
      "7/1/09  0.073471         0.007850   0.006848   0.014334     0.015833   \n",
      "\n",
      "        VWESX_LQD  \n",
      "Date               \n",
      "3/1/09   0.000975  \n",
      "4/1/09   0.015923  \n",
      "5/1/09   0.033873  \n",
      "6/1/09   0.033819  \n",
      "7/1/09   0.050450  \n",
      " \n",
      " \n",
      "SCENARIO WITH INTERVAL 1\n",
      "len rtns:  24\n",
      " \n",
      "CLUSTER ANALYSIS\n",
      "             ID CLUSTER\n",
      "EFA_EZU_EEM_EWJ  C11111\n",
      "        IWR_IWS C111121\n",
      "    IWP_SPY_XLK C111121\n",
      "    XLP_DIA_XLY C111122\n",
      "      VWEHX_IYR   C1112\n",
      "        IBB_XLV    C112\n",
      "    VWAHX_VWLTX     C12\n",
      "IEF_VFITX_VFIIX    C211\n",
      "      VUSTX_TLT    C211\n",
      "      VWESX_LQD    C212\n",
      "      GLD_VWSTX     C22\n",
      " \n",
      "DISTRIBUTION STATISTICS\n",
      "         TICKER    MEAN  STDEV  SKEW  KURT\n",
      "EFA_EZU_EEM_EWJ -0.0093 0.0878 -0.20  2.49\n",
      "        IWR_IWS -0.0126 0.0797 -0.28  3.57\n",
      "    IWP_SPY_XLK -0.0098 0.0708 -0.39  2.73\n",
      "    XLP_DIA_XLY -0.0073 0.0582 -0.27  2.90\n",
      "      VWEHX_IYR -0.0061 0.0827 -0.28  4.54\n",
      "        IBB_XLV -0.0007 0.0566 -0.32  2.54\n",
      "    VWAHX_VWLTX  0.0018 0.0218 -0.84  3.99\n",
      "IEF_VFITX_VFIIX  0.0069 0.0177  0.83  3.70\n",
      "      VUSTX_TLT  0.0072 0.0463  0.49  4.79\n",
      "      VWESX_LQD  0.0060 0.0406  0.73  5.38\n",
      "      GLD_VWSTX  0.0102 0.0345 -0.50  2.98\n",
      " \n",
      "CORRELATIONS\n",
      "                 EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  XLP_DIA_XLY  \\\n",
      "EFA_EZU_EEM_EWJ         1.000000  0.916817     0.912699     0.900544   \n",
      "IWR_IWS                 0.916817  1.000000     0.971295     0.953837   \n",
      "IWP_SPY_XLK             0.912699  0.971295     1.000000     0.921158   \n",
      "XLP_DIA_XLY             0.900544  0.953837     0.921158     1.000000   \n",
      "VWEHX_IYR               0.837394  0.922508     0.843578     0.878040   \n",
      "IBB_XLV                 0.741448  0.705134     0.716503     0.734470   \n",
      "VWAHX_VWLTX             0.360517  0.441274     0.480563     0.354687   \n",
      "IEF_VFITX_VFIIX         0.013971 -0.106271    -0.167850     0.030375   \n",
      "VUSTX_TLT               0.058273 -0.085424    -0.144152     0.017194   \n",
      "VWESX_LQD               0.592277  0.487599     0.443111     0.463336   \n",
      "GLD_VWSTX               0.232103  0.055772     0.028966     0.004860   \n",
      "\n",
      "                 VWEHX_IYR   IBB_XLV  VWAHX_VWLTX  IEF_VFITX_VFIIX  VUSTX_TLT  \\\n",
      "EFA_EZU_EEM_EWJ   0.837394  0.741448     0.360517         0.013971   0.058273   \n",
      "IWR_IWS           0.922508  0.705134     0.441274        -0.106271  -0.085424   \n",
      "IWP_SPY_XLK       0.843578  0.716503     0.480563        -0.167850  -0.144152   \n",
      "XLP_DIA_XLY       0.878040  0.734470     0.354687         0.030375   0.017194   \n",
      "VWEHX_IYR         1.000000  0.694714     0.435855        -0.126973  -0.118524   \n",
      "IBB_XLV           0.694714  1.000000     0.306767        -0.008354   0.032274   \n",
      "VWAHX_VWLTX       0.435855  0.306767     1.000000        -0.218203  -0.313648   \n",
      "IEF_VFITX_VFIIX  -0.126973 -0.008354    -0.218203         1.000000   0.901796   \n",
      "VUSTX_TLT        -0.118524  0.032274    -0.313648         0.901796   1.000000   \n",
      "VWESX_LQD         0.475478  0.544197     0.267253         0.487195   0.584591   \n",
      "GLD_VWSTX         0.131746  0.130589     0.091027         0.364796   0.265561   \n",
      "\n",
      "                 VWESX_LQD  GLD_VWSTX  \n",
      "EFA_EZU_EEM_EWJ   0.592277   0.232103  \n",
      "IWR_IWS           0.487599   0.055772  \n",
      "IWP_SPY_XLK       0.443111   0.028966  \n",
      "XLP_DIA_XLY       0.463336   0.004860  \n",
      "VWEHX_IYR         0.475478   0.131746  \n",
      "IBB_XLV           0.544197   0.130589  \n",
      "VWAHX_VWLTX       0.267253   0.091027  \n",
      "IEF_VFITX_VFIIX   0.487195   0.364796  \n",
      "VUSTX_TLT         0.584591   0.265561  \n",
      "VWESX_LQD         1.000000   0.346538  \n",
      "GLD_VWSTX         0.346538   1.000000  \n",
      "As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n",
      "\n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      " \n",
      " \n",
      "SCENARIO\n",
      "scenario_name:  6_month\n",
      "multiple:  1\n",
      "dates:  ('1/31/88', '2/5/21')\n",
      "interval:  6\n",
      "MEANS SHRUNK TOWARD ASSET PRIORS\n",
      "SCENARIO HEAD\n",
      "         EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  VWEHX_IYR  XLP_DIA_XLY  \\\n",
      "Date                                                                      \n",
      "7/1/03          0.186589  0.210850     0.200836   0.151719     0.150722   \n",
      "8/1/03          0.272425  0.273635     0.260209   0.146341     0.206856   \n",
      "9/1/03          0.349618  0.248689     0.237602   0.157988     0.169063   \n",
      "10/1/03         0.324785  0.249009     0.223690   0.137446     0.160941   \n",
      "11/1/03         0.263016  0.181995     0.157708   0.131604     0.113760   \n",
      "\n",
      "          IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  VWAHX_VWLTX  \\\n",
      "Date                                                                    \n",
      "7/1/03   0.288747        -0.004369  -0.031828  -0.005109     0.014563   \n",
      "8/1/03   0.294281        -0.013843  -0.046805  -0.021539     0.007702   \n",
      "9/1/03   0.213932         0.024248   0.021736   0.038014     0.039024   \n",
      "10/1/03  0.126205         0.010388  -0.016273   0.073512     0.022078   \n",
      "11/1/03  0.019005        -0.009249  -0.068280   0.066638     0.006916   \n",
      "\n",
      "         VWESX_LQD  \n",
      "Date                \n",
      "7/1/03    0.003763  \n",
      "8/1/03   -0.002810  \n",
      "9/1/03    0.050231  \n",
      "10/1/03   0.011738  \n",
      "11/1/03  -0.027389  \n",
      " \n",
      "SCENARIO TAIL\n",
      "         EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  VWEHX_IYR  XLP_DIA_XLY  \\\n",
      "Date                                                                      \n",
      "9/1/20          0.253978  0.309320     0.394787   0.158169     0.325736   \n",
      "10/1/20         0.156375  0.155321     0.190642   0.070557     0.140149   \n",
      "11/1/20         0.240113  0.242735     0.241511   0.101846     0.200759   \n",
      "12/1/20         0.256824  0.282465     0.253443   0.106890     0.212312   \n",
      "1/1/21          0.219075  0.215269     0.167104   0.059243     0.124341   \n",
      "\n",
      "          IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  VWAHX_VWLTX  \\\n",
      "Date                                                                    \n",
      "9/1/20   0.227552         0.014968   0.002321   0.096662     0.050573   \n",
      "10/1/20  0.039161         0.003708  -0.045199   0.055377     0.074720   \n",
      "11/1/20  0.073458         0.002746  -0.013024   0.009306     0.057733   \n",
      "12/1/20  0.123587        -0.009061  -0.062174   0.029807     0.045120   \n",
      "1/1/21   0.143409        -0.017470  -0.131689  -0.039427     0.034802   \n",
      "\n",
      "         VWESX_LQD  \n",
      "Date                \n",
      "9/1/20    0.102366  \n",
      "10/1/20   0.038858  \n",
      "11/1/20   0.067477  \n",
      "12/1/20   0.027132  \n",
      "1/1/21   -0.038992  \n",
      " \n",
      " \n",
      "SCENARIO WITH INTERVAL 6\n",
      "len rtns:  36\n",
      "len rtns:  35\n",
      "len rtns:  35\n",
      "len rtns:  35\n",
      "len rtns:  35\n",
      "len rtns:  35\n",
      " \n",
      "CLUSTER ANALYSIS\n",
      "             ID CLUSTER\n",
      "EFA_EZU_EEM_EWJ   C1111\n",
      "        IWR_IWS  C11121\n",
      "    IWP_SPY_XLK  C11122\n",
      "    XLP_DIA_XLY  C11122\n",
      "      VWEHX_IYR    C112\n",
      "        IBB_XLV     C12\n",
      "IEF_VFITX_VFIIX    C211\n",
      "      VUSTX_TLT    C211\n",
      "      GLD_VWSTX    C212\n",
      "    VWAHX_VWLTX     C22\n",
      "      VWESX_LQD     C22\n",
      " \n",
      "DISTRIBUTION STATISTICS\n",
      "         TICKER   MEAN  STDEV  SKEW  KURT\n",
      "EFA_EZU_EEM_EWJ 0.0583 0.1423 -0.50  5.13\n",
      "        IWR_IWS 0.0603 0.1303 -0.94  6.21\n",
      "    IWP_SPY_XLK 0.0620 0.1161 -1.11  7.14\n",
      "    XLP_DIA_XLY 0.0597 0.0929 -0.79  5.86\n",
      "      VWEHX_IYR 0.0552 0.1051 -0.98  8.36\n",
      "        IBB_XLV 0.0575 0.1046 -0.19  2.74\n",
      "IEF_VFITX_VFIIX 0.0245 0.0311  0.44  2.64\n",
      "      VUSTX_TLT 0.0334 0.0843  0.46  3.22\n",
      "      GLD_VWSTX 0.0230 0.0567  0.09  3.33\n",
      "    VWAHX_VWLTX 0.0271 0.0342 -0.43  3.50\n",
      "      VWESX_LQD 0.0317 0.0530  0.03  3.01\n",
      " \n",
      "CORRELATIONS\n",
      "                 EFA_EZU_EEM_EWJ   IWR_IWS  IWP_SPY_XLK  XLP_DIA_XLY  \\\n",
      "EFA_EZU_EEM_EWJ         1.000000  0.886730     0.857172     0.785054   \n",
      "IWR_IWS                 0.886730  1.000000     0.920655     0.919333   \n",
      "IWP_SPY_XLK             0.857172  0.920655     1.000000     0.934892   \n",
      "XLP_DIA_XLY             0.785054  0.919333     0.934892     1.000000   \n",
      "VWEHX_IYR               0.747856  0.878084     0.788214     0.817132   \n",
      "IBB_XLV                 0.531539  0.647528     0.715446     0.725782   \n",
      "IEF_VFITX_VFIIX        -0.405372 -0.499121    -0.433251    -0.434474   \n",
      "VUSTX_TLT              -0.463726 -0.479957    -0.400864    -0.391758   \n",
      "GLD_VWSTX               0.198253  0.000667     0.033195    -0.050918   \n",
      "VWAHX_VWLTX             0.282201  0.323326     0.322983     0.320221   \n",
      "VWESX_LQD               0.204895  0.224442     0.271398     0.261936   \n",
      "\n",
      "                 VWEHX_IYR   IBB_XLV  IEF_VFITX_VFIIX  VUSTX_TLT  GLD_VWSTX  \\\n",
      "EFA_EZU_EEM_EWJ   0.747856  0.531539        -0.405372  -0.463726   0.198253   \n",
      "IWR_IWS           0.878084  0.647528        -0.499121  -0.479957   0.000667   \n",
      "IWP_SPY_XLK       0.788214  0.715446        -0.433251  -0.400864   0.033195   \n",
      "XLP_DIA_XLY       0.817132  0.725782        -0.434474  -0.391758  -0.050918   \n",
      "VWEHX_IYR         1.000000  0.489800        -0.230570  -0.214355   0.135003   \n",
      "IBB_XLV           0.489800  1.000000        -0.381286  -0.302056  -0.244952   \n",
      "IEF_VFITX_VFIIX  -0.230570 -0.381286         1.000000   0.888927   0.449642   \n",
      "VUSTX_TLT        -0.214355 -0.302056         0.888927   1.000000   0.284981   \n",
      "GLD_VWSTX         0.135003 -0.244952         0.449642   0.284981   1.000000   \n",
      "VWAHX_VWLTX       0.590093  0.082341         0.329053   0.370719   0.273156   \n",
      "VWESX_LQD         0.478389  0.074234         0.589629   0.610261   0.404092   \n",
      "\n",
      "                 VWAHX_VWLTX  VWESX_LQD  \n",
      "EFA_EZU_EEM_EWJ     0.282201   0.204895  \n",
      "IWR_IWS             0.323326   0.224442  \n",
      "IWP_SPY_XLK         0.322983   0.271398  \n",
      "XLP_DIA_XLY         0.320221   0.261936  \n",
      "VWEHX_IYR           0.590093   0.478389  \n",
      "IBB_XLV             0.082341   0.074234  \n",
      "IEF_VFITX_VFIIX     0.329053   0.589629  \n",
      "VUSTX_TLT           0.370719   0.610261  \n",
      "GLD_VWSTX           0.273156   0.404092  \n",
      "VWAHX_VWLTX         1.000000   0.783370  \n",
      "VWESX_LQD           0.783370   1.000000  \n",
      "As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n",
      "\n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      " \n",
      " \n",
      "SCENARIO SAMPLE LENGTHS\n",
      "history: 216\n",
      "breakdown: 24\n",
      "6_month: 211\n",
      " \n",
      "NOTE: PREDICTION DISTRIBUTION INCLUDES DIFFERENT SCALES\n",
      " \n",
      "DONE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarrod/pydev2/venv/lib/python3.9/site-packages/pandas/_config/config.py:620: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n",
      "  warnings.warn(d.msg, FutureWarning)\n",
      "/Users/jarrod/pydev2/venv/lib/python3.9/site-packages/pandas/_config/config.py:620: FutureWarning: \n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      "  warnings.warn(d.msg, FutureWarning)\n",
      "/Users/jarrod/pydev2/venv/lib/python3.9/site-packages/pandas/_config/config.py:620: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n",
      "  warnings.warn(d.msg, FutureWarning)\n",
      "/Users/jarrod/pydev2/venv/lib/python3.9/site-packages/pandas/_config/config.py:620: FutureWarning: \n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      "  warnings.warn(d.msg, FutureWarning)\n",
      "/Users/jarrod/pydev2/venv/lib/python3.9/site-packages/pandas/_config/config.py:620: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n",
      "  warnings.warn(d.msg, FutureWarning)\n",
      "/Users/jarrod/pydev2/venv/lib/python3.9/site-packages/pandas/_config/config.py:620: FutureWarning: \n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      "  warnings.warn(d.msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "params=collections.OrderedDict(\n",
    "    namefile=None,\n",
    "    logfile='runxxx.txt',\n",
    "    sourcefile='comp_returns.csv',\n",
    "    prior_file='group_priors.csv',\n",
    "    codefile='equiv.csv',\n",
    "    modify='shrink_means',\n",
    "    predict_file=\"prediction_01.csv\",\n",
    "    paramfile='params01.json',\n",
    "    sourcetype='RETURNS',\n",
    "    logging=False,\n",
    "    verbose=True,\n",
    "    \n",
    "    date_format='%m/%d/%y',\n",
    "    datebounds=[1980.00,2020.1],\n",
    "    scenario_dict={\n",
    "        'history':{'multiple':1,'datetimebounds':('1/31/88','2/5/21'),'interval':1,'smodify':True,'tdiscount':.03},\n",
    "        'breakdown':{'multiple':1,'datetimebounds':('6/30/07','7/31/09'),'interval':1,'smodify':False,'tdiscount':.03}, \n",
    "        '6_month':{'multiple':1,'datetimebounds':('1/31/88','2/5/21'),'interval':6,'smodify':True,'tdiscount':.03},\n",
    "        },\n",
    "    )\n",
    "\n",
    "#run main program\n",
    "try:    \n",
    "    dummy=return_matrix_generator(params) \n",
    "    paramfile=params.get('paramfile')\n",
    "    with open(paramfile,'w') as outfile:\n",
    "        json.dump(params,outfile)\n",
    "    print(' ')\n",
    "    print('DONE!')\n",
    "except:\n",
    "    print('Unknown Input Error')\n",
    "    print(' ')\n",
    "    sys.exit()\n",
    "\n",
    "     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
