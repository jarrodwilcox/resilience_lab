{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Intended Module: resilience_optimizer\n",
    "Author: Jarrod Wilcox\n",
    "Version: 0.6\n",
    "Date: 4/13/2021\n",
    "Contact:  jarrod.wilcox@gmail.com\n",
    "\n",
    "Resilience_optimizer is a basic research program used subsequent to preprocessing by the returns_analysis program to produce more resilient portfolio allocations.  It is based on a combination of user_supplied weights for multiple scenarios, including history and scenarios in which input returns are compounded over multiple periods.  Investment return probabilities are combined with maximization of expected Rubinstein utility ln(1+Lr) to produce more resilient portfolios with less tail risk.  If all the scenarios are based on the same time horizon, a comparison with allocations based on Markowitz's mean-variance approach is also reported.\n",
    "\n",
    "Distributed as is, with MIT license, suitable for education and research only.\n",
    "\n",
    "Oldest installable dependencies tested:  python 3.8.3, numpy 1.15.4, scipy 1.4.1, pandas 1.03, jupyter 1.0.0, cvxpy 1.1.1.\n",
    "\n",
    "SAMPLE INPUTS:\n",
    "params=dict(\n",
    "    journalfile='JOURNAL.txt',\n",
    "    logfile='run001.txt',\n",
    "    sample='GITHUB EXAMPLE',\n",
    "    sourcefile='prediction_01.csv',\n",
    "    in_paramfile='params01.json',\n",
    "    Llist=[1,2,4,8,16],\n",
    "    worst=(-0.99),\n",
    "    logging=True,\n",
    "    verbose=True,\n",
    "    uweights={'history':[0.4],'breakdown':[0.2],'6_month':[0.4]},\n",
    "    )\n",
    "\n",
    "journalfile: Path to file generated to append a list of run input descriptors that can be used as a directory for various optimization run log files.\n",
    "\n",
    "logfile: Path to file that mirrors the printed program output for this set of inputs\n",
    "\n",
    "sample: String describing the run to jog the researcher's memory\n",
    "\n",
    "sourcefile: Path to a comma-delimited return file with the leftmost column labeling a scenario source and remaining column headers identifying the security (usually a ticker). WARNING:  Only sourcefiles produced by the returns_analysis preprocessor should be used.\n",
    "\n",
    "in_paramfile: Path to parameter file produced by preprocessor returns_analysis.\n",
    "    \n",
    "Llist: a vector of risk aversion coefficients, with larger numbers representing more conservatism.\n",
    "\n",
    "worst: -0.99:  Negative floating point number between 0.0 and -1.0. If the solution is feasible, this constrains candidate allocations to scenario returns so that the optimizer cannot explore impossible long-only in estimating the objective function gradient.  This is intended to prevent premature raising of errors.\n",
    "\n",
    "logging: Boolean to govern whether the log file is to be created.\n",
    "\n",
    "verbose: Boolean to provide additional reporting of tail risk potential of the output allocation\n",
    "\n",
    "uweights: Dictionary of scenario-generator labels and weights to be given to different scenario generators.  The labels must correspond to those transmitted by the returns_analysis program with positive multiple (1).\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "Produces screen output and an optional logfile with a printout of program input and results.\n",
    "    \n",
    "BACKGROUND READING:\n",
    "\n",
    "\"Better Portfolios with Higher Moments\" by Jarrod Wilcox, in the Journal of Asset Management for December,2020, provides further details on the benefits of non-parametric representations of asset return distributions, including their use in constructing more resilient portfolios managing non-normal returns.\n",
    "\n",
    "\"Expected Surplus Growth Compared with Meanâ€“Variance Optimization\", by Jarrod Wilcox and Stephen Satchell in \n",
    "The Journal of Portfolio Management Multi-Asset Special Issue 2021, 47 (4) 145-159; DOI: https://doi.org/10.3905/jpm.2021.1.209 provides further details on the approach.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import cvxpy as cp    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(sourcefile): \n",
    "    try:\n",
    "        source=pd.read_csv(sourcefile)            \n",
    "        return source\n",
    "    except:\n",
    "        print('NO ' + sourcefile + ' FOUND')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVXPY OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_with_cvxpy2(rtns,levs,mns,mcovs,headers,labels,worst,log_tdiscount,row_weight,ob):\n",
    "\n",
    "    barrier=worst+1\n",
    "    merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    nrows,ncols=rtns.shape\n",
    "    nlevs=len(levs)\n",
    "    alloc=np.ones((nlevs,ncols),dtype='float64')\n",
    "    prtns=np.zeros((nlevs,nrows),dtype='float64')\n",
    "    \n",
    "    xx=cp.Variable(ncols)\n",
    "    for i in range(nlevs):\n",
    "        lev=levs[i]\n",
    "        levreturn=(rtns*lev)\n",
    "        print(\"Risk Aversion: \",lev)\n",
    "        \n",
    "        if ob=='MV':           \n",
    "            constraints =[sum(xx)==1, 0<=xx, xx<=1] #Long-only portfolios                   \n",
    "            objective=cp.Minimize(-cp.sum(cp.multiply(mns,xx)) + lev*cp.quad_form(xx,mcovs)/2.0)\n",
    "            prob=cp.Problem(objective,constraints)\n",
    "            result=prob.solve(eps_abs=1e-7,eps_rel=1e-7)\n",
    "            xxvalue=xx.value\n",
    "            prtns[i]=np.dot(rtns,xxvalue)\n",
    "            merit['M_objective'][headers[i]]= np.sum(mns*xxvalue) - levs[i]*np.dot(np.dot(xxvalue,mcovs),xxvalue.T)/2.0\n",
    "            merit['W_objective'][headers[i]]= np.sum(np.multiply(row_weight,(np.log1p(np.dot(levreturn,xxvalue.T))+log_tdiscount)))   \n",
    "\n",
    "        elif ob=='LLS':\n",
    "            constraints =[sum(xx)==1, 0<=xx, xx<=1, -1.0+barrier <= levreturn @ xx ] #Long-only portfolios                              \n",
    "            objective=cp.Maximize(cp.sum(cp.multiply(row_weight,cp.log1p(levreturn @ xx)+log_tdiscount)))\n",
    "            prob=cp.Problem(objective,constraints)\n",
    "            result=prob.solve(abstol=1e-7,reltol=1e-7,verbose=False)/nrows\n",
    "            xxvalue=xx.value\n",
    "            if xxvalue is None:                \n",
    "                print('WARNING!!!! cvxpy problem appears not feasible.')\n",
    "                raise\n",
    "            prtns[i]=np.dot(rtns,xxvalue)\n",
    "            merit['M_objective'][headers[i]]= sum(mns*xxvalue) - levs[i]*np.dot(np.dot(xxvalue,mcovs),xxvalue.T)/2.0\n",
    "            merit['W_objective'][headers[i]]= np.sum(np.multiply(row_weight,(np.log1p(np.dot(levreturn,xxvalue.T))+log_tdiscount)))       \n",
    "        alloc[i]=xxvalue \n",
    "        merit['norm2'][headers[i]] = np.dot(xxvalue,xxvalue)        \n",
    "    \n",
    "    return (prtns[::].T,alloc[::],pd.DataFrame.copy(merit,deep=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRINT ALLOCATION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_alloc(alloc_df):   \n",
    "    ilist=[]\n",
    "    rowlist=[]\n",
    "    for i,row in enumerate(alloc_df.values):\n",
    "        for v in row:\n",
    "            if abs(v)>.00001:\n",
    "                ilist.append(alloc_df.index[i])\n",
    "                rowlist.append([str(x) for x in row])                \n",
    "                break\n",
    "    chosen_df=pd.DataFrame(rowlist,index=ilist,columns=alloc_df.columns)       \n",
    "    print(chosen_df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIND BEST ALLOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_allocation(rtns_df,worst,levs,meta_df=False,valid_mv=None,verbose=True): \n",
    "    rtns_df.to_csv('temp1.csv')\n",
    "    rtns=rtns_df.values    \n",
    "    rtns_cols=rtns_df.columns\n",
    "      \n",
    "    means=np.mean(rtns_df,axis=0)\n",
    "    covs=np.cov(rtns_df.T)\n",
    "    \n",
    "    mpreturns=None\n",
    "    malloc=None\n",
    "    M_merit=None\n",
    "    \n",
    "    log_tdiscount=0\n",
    "    row_weight=1\n",
    "    if not meta_df is None:\n",
    "        log_tdiscount=meta_df['log_tdiscount'].values\n",
    "        row_weight=meta_df['row_weight'].values  \n",
    "    \n",
    "    headers=['L:'+x for x in list(map(str,levs))]\n",
    "    labels=['W_objective','M_objective','norm2']\n",
    "\n",
    "    if verbose and valid_mv:\n",
    "        print(' ')    \n",
    "        print('RUNNING MEAN-VARIANCE OPTIMIZATION')\n",
    "    if valid_mv:\n",
    "        mpreturns,malloc,M_merit=optim_with_cvxpy2(rtns,\n",
    "            levs,means,covs,headers,labels,worst,log_tdiscount,row_weight,ob=\"MV\")\n",
    "    if verbose:\n",
    "        print(' ')\n",
    "        print('RUNNING EXPECTED SURPLUS GROWTH OPTIMIZATION')\n",
    "    wpreturns,walloc,W_merit=optim_with_cvxpy2(rtns,\n",
    "        levs,means,covs,headers,labels,worst,log_tdiscount,row_weight,ob=\"LLS\")\n",
    "    \n",
    "    mpreturns_df=pd.DataFrame(mpreturns,index=rtns_df.index)\n",
    "    wpreturns_df=pd.DataFrame(wpreturns,index=rtns_df.index)\n",
    "    \n",
    "    if verbose:\n",
    "        if valid_mv:\n",
    "            print(' ')\n",
    "            print('ALLOCATIONS TO MAXIMIZE MEAN-VARIANCE')  \n",
    "            malloc_df=pd.DataFrame(np.round(malloc,3),columns=rtns_df.columns,index=headers).T\n",
    "            print_alloc(malloc_df)\n",
    "        print(' ')\n",
    "        print('ALLOCATIONS TO MAXIMIZE EXPECTED SURPLUS GROWTH')\n",
    "        walloc_df=pd.DataFrame(np.round(walloc,3),columns=rtns_df.columns,index=headers).T\n",
    "        print_alloc(walloc_df)\n",
    "        print(' ')\n",
    "        if valid_mv:\n",
    "            print('IN-SAMPLE ALLOCATION MERIT FROM MEAN-VARIANCE')\n",
    "            print(M_merit[['W_objective','M_objective','norm2']].head(10))\n",
    "            print(' ')    \n",
    "        print('IN-SAMPLE ALLOCATION MERIT FROM EXPECTED SURPLUS GROWTH')\n",
    "        print(W_merit[['W_objective','M_objective','norm2']].head(10))\n",
    "        print(' ')\n",
    "    \n",
    "    return (wpreturns_df,mpreturns_df,walloc,malloc,W_merit,M_merit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIBE RETURN DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtn_summary(returns_df):\n",
    "    tickers=returns_df.columns   \n",
    "    rtns=returns_df.values\n",
    "    print('len rtns: ',len(rtns))\n",
    "    means=np.mean(rtns,axis=0)\n",
    "    covs=np.cov(rtns.T)\n",
    "    stdevs=np.std(rtns,axis=0)        \n",
    "    corrs=np.corrcoef(rtns.T)\n",
    "    skews=stats.skew(rtns,axis=0)        \n",
    "    kurts=stats.kurtosis(rtns,axis=0,fisher=False)\n",
    "    \n",
    "    corrs_df=pd.DataFrame(corrs,columns=tickers,index=tickers)\n",
    "    descript_df=pd.DataFrame({'TICKER':tickers,'MEAN':np.round(means,4),\n",
    "        'STDEV':np.round(stdevs,4),'SKEW':np.round(skews,2),'KURT':np.round(kurts,2)})\n",
    "    \n",
    "    return(descript_df,corrs_df,count) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTEND ALLOCATION CONSEQUENCES TO PORTFOLIO RETURN CHARACTERISTICS IN SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_xray(merit,objective,levs,pmean,pstd,pskew,pkurt):\n",
    "    #X-ray on optimal in-sample surplus log growth rate objective\n",
    "    exp_utility=[x for x in merit[objective].values]\n",
    "    xray=pd.DataFrame([levs,exp_utility,pmean,pstd,pskew,pkurt]).T\n",
    "    xray.columns=['Leverage','Exp_Log_Gr','mean','stdev','skewness','kurtosis']\n",
    "    \n",
    "    xray['Q'] = xray['Leverage']*xray['stdev']/(1+xray['Leverage']*xray['mean'])\n",
    "    headers=['L:'+x for x in list(map(str,levs))]\n",
    "    Q_df=pd.DataFrame([headers,xray['Q']]).T\n",
    "    Q_df.columns=['Leverage','Q']\n",
    "    with pd.option_context('display.float_format', '{:,.3f}'.format):\n",
    "        print(Q_df.to_string(index=False))\n",
    "    \n",
    "    xray['First']= np.log1p(xray['Leverage']*xray['mean'])\n",
    "    xray['Second']=-(xray['Q']**2)/2\n",
    "    xray['Third']=xray['skewness']*(xray['Q']**3)/3\n",
    "    xray['Fourth']=-xray['kurtosis']*(xray['Q']**4)/4\n",
    "    xray['Residual']=xray['Exp_Log_Gr']-xray['First']-xray['Second']-xray['Third']-xray['Fourth']\n",
    "    xray=xray.drop(['mean','stdev','skewness','kurtosis','Q'],axis=1)\n",
    "    print(' ')\n",
    "    print('COMPOSITION BY RETURN DISTRIBUTION MOMENTS:')\n",
    "    print(' ')\n",
    "    print(xray.to_string(index=False))    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_portfolio_returns(wprtns,mprtns,wmerit,mmerit,levs,verbose=True,valid_mv=None):\n",
    "    #COMPARE OUTPUTS ON TRADITIONAL STATISTICS\n",
    "    print(' ')\n",
    "    if verbose:\n",
    "        wpmean=pd.Series(np.mean(wprtns,axis=0))\n",
    "        wpstd=pd.Series(np.std(wprtns,axis=0))\n",
    "        wpskew=pd.Series(stats.skew(wprtns,axis=0))\n",
    "        wpkurt=pd.Series(stats.kurtosis(wprtns,axis=0,fisher=False))    \n",
    "\n",
    "        mpmean=pd.Series(np.mean(mprtns,axis=0))\n",
    "        mpstd=pd.Series(np.std(mprtns,axis=0))\n",
    "        mpskew=pd.Series(stats.skew(mprtns,axis=0))\n",
    "        mpkurt=pd.Series(stats.kurtosis(mprtns,axis=0,fisher=False))\n",
    "    \n",
    "        pdescribe1=pd.DataFrame({'WMEAN': np.round(wpmean,4),'MMEAN':np.round(mpmean,4)})\n",
    "        pdescribe2=pd.DataFrame({'WSTD': np.round(wpstd,4),'MSTD':np.round(mpstd,4)})\n",
    "        pdescribe3=pd.DataFrame({'WSKEW': np.round(wpskew,3),'MSKEW':np.round(mpskew,3)})\n",
    "        pdescribe4=pd.DataFrame({'WKURT': np.round(wpkurt,3),'MKURT':np.round(mpkurt,3)})   \n",
    "        pdescribe=pd.concat([pdescribe1,pdescribe2,pdescribe3,pdescribe4],axis=1,sort=False)\n",
    "        pdescribe.index=['L:'+x for x in list(map(str,levs))]\n",
    "        print('COMPARE PORTFOLIO STATISTICS')\n",
    "        print(pdescribe)\n",
    "        print(' ')\n",
    "        \n",
    "        if verbose and valid_mv:\n",
    "            print('IN_SAMPLE SURPLUS GROWTH OBJECTIVE WITH MEAN-VARIANCE OPTIMIZATION')\n",
    "            show_xray(mmerit,'W_objective',levs,mpmean,mpstd,mpskew,mpkurt)\n",
    "            print(' ')\n",
    "        print('IN-SAMPLE SURPLUS GROWTH OBJECTIVE WITH SURPLUS GROWTH OPTIMIZATION')\n",
    "        show_xray(wmerit,'W_objective',levs,wpmean,wpstd,wpskew,wpkurt)\n",
    "        print(' ')\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESEARCH RECORDKEEPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters2(params):\n",
    "    for key,value in params.items():\n",
    "        print(\"{0}: {1}\".format(key,value))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ METADATA FOR USE IN WEIGHTED OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_metadata(in_paramfile=None,uweights=None,sources_df=None):\n",
    "    #read parameters from return_analyze program if input is assumed to be prediction returns from it\n",
    "    #combine with sources_df stripped from return data file\n",
    "    if not in_paramfile is None:\n",
    "        try:\n",
    "            with open(in_paramfile,'r') as infile:\n",
    "                in_params=json.load(infile)\n",
    "             \n",
    "            #get tdiscount log to subtract from utility\n",
    "            init_scenario_dict_df=pd.DataFrame(in_params.get('scenario_dict')).T\n",
    "            scenario_dict_df=pd.DataFrame(init_scenario_dict_df[['interval','tdiscount']])\n",
    "\n",
    "            # calculate time discount assuming interval data in months\n",
    "            scenario_dict_df['log_tdiscount']=[-x[0]*np.log1p(x[1])/12.0 for x in scenario_dict_df.values]\n",
    "            \n",
    "            #get count of obs in each scenario without testing for valid keys\n",
    "            counts=sources_df['dist_source'].value_counts()\n",
    "            counts_df=pd.DataFrame([counts]).T\n",
    "            counts_df.columns=['count']\n",
    "            scenario_dict_df=scenario_dict_df.join(counts_df)\n",
    "       \n",
    "            #get desired scenario weights and translate to rows\n",
    "            uweights_df=pd.DataFrame(uweights).T\n",
    "            uweights_df.columns=['weight'] \n",
    "            \n",
    "            #adjust weights to quasi-probabilities\n",
    "            sumwt=np.sum(uweights_df['weight'].values)\n",
    "            uweights_df['weight']= uweights_df['weight']/sumwt\n",
    "            \n",
    "            scenario_dict_df=scenario_dict_df.join(uweights_df)\n",
    "            scenario_dict_df['row_weight']=scenario_dict_df['weight']/scenario_dict_df['count']\n",
    "\n",
    "            intervals=scenario_dict_df['interval'].values #save interval information\n",
    "            scenario_dict_df=scenario_dict_df[['log_tdiscount','row_weight']] \n",
    "            print(' ')\n",
    "            print('INPUT SCENARIO METADATA')\n",
    "            print(scenario_dict_df)\n",
    "            \n",
    "            #join with sources_df stripped from return data file\n",
    "            scenario_dict_df['dist_source']=scenario_dict_df.index.values       \n",
    "            sources_df=sources_df.join(scenario_dict_df.set_index('dist_source'),on='dist_source')\n",
    "\n",
    "            # check to see if okay to do mean-variance comparison\n",
    "            temp=[x for i,x in enumerate(intervals) if uweights_df['weight'].values[i] > 0 ]\n",
    "            valid_mv=(max(temp)==min(temp))\n",
    "            print(' ')\n",
    "            print('Okay to compare with mean-variance is ',valid_mv)\n",
    "            \n",
    "            return(sources_df,valid_mv,init_scenario_dict_df,uweights_df)           \n",
    "        except:\n",
    "            print('Good param file not found.')\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_optimizer(params={}):    \n",
    "    journalfile=params.get('journalfile')\n",
    "    logfile=params.get('logfile')\n",
    "    sample=params.get('sample')\n",
    "    sourcefile=params.get('sourcefile')\n",
    "    in_paramfile=params.get('in_paramfile')\n",
    "    Llist=params.get('Llist')\n",
    "    worst=params.get('worst')\n",
    "    logging=params.get('logging')\n",
    "    verbose=params.get('verbose')\n",
    "    clusterfile=params.get('clusterfile')\n",
    "    uweights=params.get('uweights')    \n",
    "    \n",
    "    #See import dependencies in first cell\n",
    "    if logging:\n",
    "        #record run description in journalfile\n",
    "        orig_stdout = sys.stdout\n",
    "        e=open(journalfile, 'a')\n",
    "        sys.stdout=e\n",
    "        print(' ')\n",
    "        print_parameters2(params)\n",
    "        e.close()\n",
    "        \n",
    "        #record results in logfile\n",
    "        f = open(logfile, 'w')\n",
    "        sys.stdout = f\n",
    "    \n",
    "        #record control parameters\n",
    "        print_parameters2(params)\n",
    "             \n",
    "    #Read in Returns\n",
    "    returns_df=load_source(sourcefile)\n",
    "    \n",
    "    #Extract scenario source\n",
    "    print(' ')\n",
    "    sources_df=None\n",
    "    col0=returns_df.iloc[:,0]   #first column\n",
    "    if isinstance(col0.iloc[0],str):\n",
    "        sources_df=pd.DataFrame(col0)\n",
    "        sources_df.columns=['dist_source']       \n",
    "        returns_df=returns_df.drop([returns_df.columns.values[0]],axis=1)\n",
    "    \n",
    "    #read parameters from return_analyze program\n",
    "    meta_df, valid_mv, init_scenario_dict_df, uweights_df=read_metadata(in_paramfile,uweights,sources_df)\n",
    "    print('')\n",
    "        \n",
    "    if verbose and valid_mv:\n",
    "        sdict=pd.concat([init_scenario_dict_df,uweights_df], axis=1)\n",
    "        temp=[x[1] for x in sdict[['weight','interval']].values if x[0]>0.0]\n",
    "        if len(temp)>0 and temp[0]==1:\n",
    "            descript_df,corrs_df,count=rtn_summary(returns_df)\n",
    "            print('INPUT RETURN MATRIX PARAMETERS')\n",
    "            print(descript_df)\n",
    "            \n",
    "    # Do mean-variance and log leveraged surplus optimizations\n",
    "    (wpreturns_df,mpreturns_df,learn_walloc,learn_malloc,learn_W_merit,learn_M_merit) = find_best_allocation(\n",
    "        returns_df,worst,Llist,meta_df,valid_mv)\n",
    "    if verbose:\n",
    "        #describe portfolio return statistics for different leverages\n",
    "        describe_portfolio_returns(wpreturns_df.values,\n",
    "            mpreturns_df.values,learn_W_merit,learn_M_merit,Llist,verbose,valid_mv)\n",
    "\n",
    "    print(' ')\n",
    "    if logging:\n",
    "        #close logfile and print it on terminal\n",
    "        f.close()\n",
    "        sys.stdout = orig_stdout\n",
    "\n",
    "        h=open(logfile,'r')\n",
    "        for line in h:\n",
    "            if len(line)>0:          \n",
    "                print(line[:-1])          \n",
    "        h.close()\n",
    "    print(' ')\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN: SET PARAMETERS AND CALL RESEARCH OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journalfile: JOURNAL.txt\n",
      "logfile: runxxx.txt\n",
      "sample: GITHUB EXAMPLE\n",
      "sourcefile: prediction_01.csv\n",
      "in_paramfile: params01.json\n",
      "Llist: [1, 2, 4, 8, 16]\n",
      "worst: -0.99\n",
      "logging: True\n",
      "verbose: True\n",
      "uweights: {'history': [0.4], 'breakdown': [0.2], '6_month': [0.4]}\n",
      " \n",
      " \n",
      "INPUT SCENARIO METADATA\n",
      "           log_tdiscount  row_weight\n",
      "history        -0.002463    0.001852\n",
      "breakdown      -0.002463    0.008333\n",
      "6_month        -0.014779    0.001896\n",
      " \n",
      "Okay to compare with mean-variance is  False\n",
      "\n",
      " \n",
      "RUNNING EXPECTED SURPLUS GROWTH OPTIMIZATION\n",
      "Risk Aversion:  1\n",
      "Risk Aversion:  2\n",
      "Risk Aversion:  4\n",
      "Risk Aversion:  8\n",
      "Risk Aversion:  16\n",
      " \n",
      "ALLOCATIONS TO MAXIMIZE EXPECTED SURPLUS GROWTH\n",
      "                   L:1    L:2    L:4    L:8   L:16\n",
      "XLP_DIA_XLY      0.435  0.437  0.332  0.214  0.126\n",
      "IBB_XLV          0.565   0.44  0.308  0.215  0.136\n",
      "IEF_VFITX_VFIIX    0.0    0.0    0.0  0.335  0.738\n",
      "VUSTX_TLT          0.0  0.124   0.36  0.236    0.0\n",
      " \n",
      "IN-SAMPLE ALLOCATION MERIT FROM EXPECTED SURPLUS GROWTH\n",
      "     W_objective M_objective     norm2\n",
      "L:1     0.016407    0.029184  0.508386\n",
      "L:2      0.03496    0.026293  0.399271\n",
      "L:4     0.065223      0.0226  0.334697\n",
      "L:8     0.107976    0.017821  0.259924\n",
      "L:16    0.175298    0.013817  0.578957\n",
      " \n",
      " \n",
      "COMPARE PORTFOLIO STATISTICS\n",
      "       WMEAN  MMEAN    WSTD  MSTD  WSKEW  MSKEW  WKURT  MKURT\n",
      "L:1   0.0320    NaN  0.0748   NaN  0.166    NaN  5.073    NaN\n",
      "L:2   0.0304    NaN  0.0636   NaN  0.171    NaN  5.109    NaN\n",
      "L:4   0.0272    NaN  0.0477   NaN  0.255    NaN  4.045    NaN\n",
      "L:8   0.0227    NaN  0.0349   NaN  0.391    NaN  3.355    NaN\n",
      "L:16  0.0185    NaN  0.0242   NaN  0.506    NaN  2.979    NaN\n",
      " \n",
      "IN-SAMPLE SURPLUS GROWTH OBJECTIVE WITH SURPLUS GROWTH OPTIMIZATION\n",
      "Leverage     Q\n",
      "     L:1 0.072\n",
      "     L:2  0.12\n",
      "     L:4 0.172\n",
      "     L:8 0.236\n",
      "    L:16 0.299\n",
      " \n",
      "COMPOSITION BY RETURN DISTRIBUTION MOMENTS:\n",
      " \n",
      " Leverage  Exp_Log_Gr    First    Second    Third    Fourth  Residual\n",
      "      1.0    0.016407 0.031487 -0.002627 0.000021 -0.000035 -0.012439\n",
      "      2.0    0.034960 0.058930 -0.007196 0.000098 -0.000265 -0.016608\n",
      "      4.0    0.065223 0.103153 -0.014823 0.000434 -0.000889 -0.022653\n",
      "      8.0    0.107976 0.166910 -0.027928 0.001721 -0.002617 -0.030110\n",
      "     16.0    0.175298 0.259492 -0.044656 0.004500 -0.005941 -0.038097\n",
      " \n",
      " \n",
      " \n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "params=dict(\n",
    "    journalfile='JOURNAL.txt',\n",
    "    logfile='runxxx.txt',\n",
    "    sample='GITHUB EXAMPLE',\n",
    "    sourcefile='prediction_01.csv',\n",
    "    in_paramfile='params01.json',\n",
    "    Llist=[1,2,4,8,16],\n",
    "    worst=(-0.99),\n",
    "    logging=True,\n",
    "    verbose=True,\n",
    "    uweights={'history':[0.4],'breakdown':[0.2],'6_month':[0.4]},\n",
    "    )\n",
    "\n",
    "#run main program\n",
    "optimizer_output=None\n",
    "try:   \n",
    "    optimizer_output=research_optimizer(params)   \n",
    "    print('DONE!')\n",
    "except:\n",
    "    print('Goodbye!!')\n",
    "    print(' ')\n",
    "    sys.exit()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
